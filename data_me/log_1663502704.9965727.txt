What are the strengths and weaknesses of the above argument? How would you improve it? Why? How could you justify your changes? If you would like to learn more about AGI, please refer to the following to-read list: Bostrom, N. (2014). Superintelligence: Paths, Dangers, Strategies. Oxford: Oxford University Press. Bostrom, N. (2012). Philosophical Implications of Openness in AI. In Artificial Intelligence and Life in 2030 (pp. 24-37). AAAI Press. McDermott, D., & Bostrom, N. (2012). Alignment for advanced machine learning systems. Future of Life Institute. Turchin, A. (2013). The Phenomenon of Science. Cambridge, Massachusetts: The MIT Press. Turchin, A. (2011). War and Peace and War: The Life Cycles of Imperial Nations. New York: Pi Press. Vinge, V. (1993). The Coming Technological Singularity: How to Survive in the Post-Human Era. San Diego: Vision-Press Books. Yudkowsky, E.